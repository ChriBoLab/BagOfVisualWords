{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εισαγωγή των απαραίτητων βιβλιοθηκών."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from sklearn.cluster import MiniBatchKMeans #KMeans\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth,AffinityPropagation\n",
    "\n",
    "import numpy as np\n",
    "#import secondary functions that will be used very frequent\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Δημιουργούμε ένα dataframe στο οποίο θα αποθηκεύσουμε τα αποτελέσματα μας."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['FeatureExtraction', 'Clustering Detection','Train Data ratio',\n",
    "           'Classifier Used','Accuracy(tr)', 'Precision(tr)',\n",
    "           'Recal(tr)', 'F1 score (tr)','Accuracy (te)', 'Precision (te)',\n",
    "           'Recal(te)', 'F1 score (te)']\n",
    "\n",
    "results_DF = pd.DataFrame(columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Συνάρτηση με την οποία διαβάζουμε όλες τις εικόνες και δημιουργούμε ένα dictionary όπου περιέχει όλες τις εικόνες ανά κατηγορία."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a dictionary that holds all images category by category.\n",
    "def load_images_from_folder(folder, inputImageSize ):\n",
    "    images = {}\n",
    "    for filename in os.listdir(folder):\n",
    "        category = []\n",
    "        path = folder + \"/\" + filename\n",
    "        for name in os.listdir(path):\n",
    "            img = cv2.imread(path + \"/\" + name)\n",
    "            #print(' .. parsing image', cat)\n",
    "            if img is not None:\n",
    "                # grayscale it\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                #resize it, if necessary\n",
    "                img = cv2.resize(img, (inputImageSize[0], inputImageSize[1]))\n",
    "\n",
    "                category.append(img)\n",
    "        images[filename] = category\n",
    "        print(' . Finished parsing images. What is next?')\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a fixed image size to work with\n",
    "inputImageSize = [200, 200, 3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainImagesFilePath ='Dataset/Train'\n",
    "TestImagesFilePath = 'Dataset/Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Διαβάζουμε τις εικόνες προς εκπαίδευση."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . Finished parsing images. What is next?\n",
      " . Finished parsing images. What is next?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the train images\n",
    "trainImages = load_images_from_folder(TrainImagesFilePath, inputImageSize)  # take all images category by category for train set\n",
    "trainImages.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates descriptors using an approach of your choise. e.g. ORB, SIFT, SURF, FREAK, MOPS, etc\n",
    "# Takes first parameter that is images dictionary\n",
    "# Takes second parameter that is the Detector\n",
    "# Return an array whose first index holds the decriptor_list without an order\n",
    "# And the second index holds the sift_vectors dictionary which holds the descriptors but this is seperated class by class\n",
    "def detector_features(images, detectorToUse):\n",
    "    print(' . start detecting points and calculating features for a given image set')\n",
    "    detector_vectors = {}\n",
    "    descriptor_list = []\n",
    "    \n",
    "    for nameOfCategory, availableImages in images.items():\n",
    "        features = []\n",
    "        for img in availableImages: # reminder: val\n",
    "            kp, des = detectorToUse.detectAndCompute(img, None)\n",
    "\n",
    "            descriptor_list.extend(des)\n",
    "            features.append(des)\n",
    "        detector_vectors[nameOfCategory] = features\n",
    "        print(' . finished detecting points and calculating features for a given image set')\n",
    "    return [descriptor_list, detector_vectors] # be aware of the []! this is ONE output as a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . start detecting points and calculating features for a given image set\n",
      " . finished detecting points and calculating features for a given image set\n",
      " . finished detecting points and calculating features for a given image set\n"
     ]
    }
   ],
   "source": [
    "trainDataFeatures_SIFT = detector_features(trainImages, cv2.xfeatures2d.SIFT_create())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . start detecting points and calculating features for a given image set\n",
      " . finished detecting points and calculating features for a given image set\n",
      " . finished detecting points and calculating features for a given image set\n"
     ]
    }
   ],
   "source": [
    "trainDataFeatures_ORB = detector_features(trainImages, cv2.ORB_create())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . start detecting points and calculating features for a given image set\n",
      " . finished detecting points and calculating features for a given image set\n",
      " . finished detecting points and calculating features for a given image set\n"
     ]
    }
   ],
   "source": [
    "trainDataFeatures_SURF = detector_features(trainImages, cv2.xfeatures2d.SURF_create(400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the descriptor list which is unordered one\n",
    "TrainDescriptorList_SIFT = trainDataFeatures_SIFT[0]\n",
    "TrainDescriptorList_ORB = trainDataFeatures_ORB[0]\n",
    "TrainDescriptorList_SURF = trainDataFeatures_SURF[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6784"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainDescriptorList_SIFT.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4355"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainDescriptorList_SURF.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A k-means clustering algorithm who takes 2 parameter which is number\n",
    "# of cluster(k) and the other is descriptors list(unordered 1d array)\n",
    "# Returns an array that holds central points.\n",
    "def kmeansVisualWordsCreation(k, descriptor_list):\n",
    "    print(' . calculating central points for the existing feature values.')\n",
    "    #kmeansModel = KMeans(n_clusters = k, n_init=10)\n",
    "    batchSize = np.ceil(descriptor_list.__len__()/50).astype('int')\n",
    "    kmeansModel = MiniBatchKMeans(n_clusters=k, batch_size=batchSize, verbose=0)\n",
    "    kmeansModel.fit(descriptor_list)\n",
    "    visualWords = kmeansModel.cluster_centers_ # a.k.a. centers of reference\n",
    "    print(' . done calculating central points for the given feature set.Centers are ', len(kmeansModel.cluster_centers_))\n",
    "    return visualWords, kmeansModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A mean shift clustering algorithm who takes 1 parameter which is \n",
    "# descriptors list(unordered 1d array)\n",
    "# Returns an array that holds central points.\n",
    "def run_mean_shift(descriptor_list, bbandwidth):\n",
    "    \n",
    "    # The following bandwidth can be automatically detected using\n",
    "    #bandwidth = estimate_bandwidth(descriptor_list)\n",
    "    #print(bandwidth)\n",
    "    ms = MeanShift(bandwidth = bbandwidth).fit(descriptor_list)\n",
    "    \n",
    "    visualWords = ms.cluster_centers_\n",
    "    print(' . done calculating central points for the given feature set.')\n",
    "    print('Centers is', len(ms.cluster_centers_))\n",
    "    return visualWords, ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . done calculating central points for the given feature set.\n",
      "Centers is 2731\n"
     ]
    }
   ],
   "source": [
    "#create the central points for the histograms using mean shift.\n",
    "visualWords_SIFT_ms, TrainedMsModel_SIFT = run_mean_shift(TrainDescriptorList_SIFT\n",
    "                                                         ,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . done calculating central points for the given feature set.\n",
      "Centers is 3329\n"
     ]
    }
   ],
   "source": [
    "visualWords_ORB_ms, TrainedMsModel_ORB = run_mean_shift(TrainDescriptorList_ORB\n",
    "                                                       ,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . done calculating central points for the given feature set.\n",
      "Centers is 115\n"
     ]
    }
   ],
   "source": [
    "visualWords_SURF_ms, TrainedMsModel_SURF = run_mean_shift(TrainDescriptorList_SURF\n",
    "                                                         ,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . calculating central points for the existing feature values.\n",
      " . done calculating central points for the given feature set.Centers are  20\n",
      " . calculating central points for the existing feature values.\n",
      " . done calculating central points for the given feature set.Centers are  20\n",
      " . calculating central points for the existing feature values.\n",
      " . done calculating central points for the given feature set.Centers are  20\n"
     ]
    }
   ],
   "source": [
    "#create the central points for the histograms using k means.\n",
    "#here we use a rule of the thumb to create the expected number of cluster centers\n",
    "numberOfClasses = trainImages.__len__() #retrieve num of classes from dictionary\n",
    "possibleNumOfCentersToUse = 10 * numberOfClasses\n",
    "\n",
    "visualWords_SIFT, TrainedKmeansModel_SIFT = kmeansVisualWordsCreation(possibleNumOfCentersToUse,\n",
    "                                                            TrainDescriptorList_SIFT)\n",
    "\n",
    "visualWords_ORB, TrainedKmeansModel_ORB = kmeansVisualWordsCreation(possibleNumOfCentersToUse,\n",
    "                                                            TrainDescriptorList_ORB)\n",
    "\n",
    "visualWords_SURF, TrainedKmeansModel_SURF = kmeansVisualWordsCreation(possibleNumOfCentersToUse,\n",
    "                                                            TrainDescriptorList_SURF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Το επόμενο βήμα είναι να δημιουργήσουμε τα ιστογράμματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the sift feature values that is seperated class by class for train data,\n",
    "#we need this to calculate the histograms\n",
    "trainBoVWFeatureVals_SIFT = trainDataFeatures_SIFT[1]\n",
    "\n",
    "trainBoVWFeatureVals_ORB = trainDataFeatures_ORB[1]\n",
    "\n",
    "trainBoVWFeatureVals_SURF = trainDataFeatures_SURF[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapFeatureValsToHistogram (DataFeaturesByClass, visualWords, MODEL):\n",
    "    #depenting on the approach you may not need to use all inputs\n",
    "    histogramsList = []\n",
    "    targetClassList = []\n",
    "    numberOfBinsPerHistogram = visualWords.shape[0]\n",
    "\n",
    "    for categoryIdx, featureValues in DataFeaturesByClass.items():\n",
    "        for tmpImageFeatures in featureValues: #yes, we check one by one the values in each image for all images\n",
    "            tmpImageHistogram = np.zeros(numberOfBinsPerHistogram)\n",
    "            tmpIdx = list(MODEL.predict(tmpImageFeatures))\n",
    "            clustervalue, visualWordMatchCounts = np.unique(tmpIdx, return_counts=True)\n",
    "            tmpImageHistogram[clustervalue] = visualWordMatchCounts\n",
    "            # do not forget to normalize the histogram values\n",
    "            numberOfDetectedPointsInThisImage = tmpIdx.__len__()\n",
    "            tmpImageHistogram = tmpImageHistogram/numberOfDetectedPointsInThisImage\n",
    "\n",
    "            #now update the input and output coresponding lists\n",
    "            histogramsList.append(tmpImageHistogram)\n",
    "            targetClassList.append(categoryIdx)\n",
    "\n",
    "    return histogramsList, targetClassList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the train input train output format\n",
    "trainHistogramsList_SIFT, trainTargetsList_SIFT = mapFeatureValsToHistogram(\n",
    "    trainBoVWFeatureVals_SIFT, visualWords_SIFT, TrainedKmeansModel_SIFT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the train input train output format\n",
    "trainHistogramsList_ORB, trainTargetsList_ORB = mapFeatureValsToHistogram(\n",
    "    trainBoVWFeatureVals_ORB, visualWords_ORB, TrainedKmeansModel_ORB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the train input train output format\n",
    "trainHistogramsList_SURF, trainTargetsList_SURF = mapFeatureValsToHistogram(\n",
    "    trainBoVWFeatureVals_SURF, visualWords_SURF, TrainedKmeansModel_SURF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the train input train output format\n",
    "trainHistogramsList_SIFT_ms, trainTargetsList_SIFT_ms = mapFeatureValsToHistogram(\n",
    "    trainBoVWFeatureVals_SIFT, visualWords_SIFT_ms, TrainedMsModel_SIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the train input train output format\n",
    "trainHistogramsList_ORB_ms, trainTargetsList_ORB_ms = mapFeatureValsToHistogram(\n",
    "    trainBoVWFeatureVals_ORB, visualWords_ORB_ms, TrainedMsModel_ORB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the train input train output format\n",
    "trainHistogramsList_SURF_ms, trainTargetsList_SURF_ms = mapFeatureValsToHistogram(\n",
    "    trainBoVWFeatureVals_SURF, visualWords_SURF_ms, TrainedMsModel_SURF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.57\n",
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of svm_SIFT classifier on training set: 0.79\n"
     ]
    }
   ],
   "source": [
    "X_train_SIFT = np.stack(trainHistogramsList_SIFT, axis= 0)\n",
    "# Convert Categorical Data For Scikit-Learn\n",
    "\n",
    "labelEncoder_SIFT = preprocessing.LabelEncoder()\n",
    "labelEncoder_SIFT.fit(trainTargetsList_SIFT)\n",
    "#convert the categories from strings to names\n",
    "y_train_SIFT = labelEncoder_SIFT.transform(trainTargetsList_SIFT)\n",
    "\n",
    "knn_SIFT = KNeighborsClassifier()\n",
    "knn_SIFT.fit(X_train_SIFT, y_train_SIFT)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'.format(knn_SIFT.score(X_train_SIFT, y_train_SIFT)))\n",
    "\n",
    "clf_SIFT = DecisionTreeClassifier().fit(X_train_SIFT, y_train_SIFT)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(clf_SIFT.score(X_train_SIFT, y_train_SIFT)))\n",
    "\n",
    "svm_SIFT = SVC()\n",
    "svm_SIFT.fit(X_train_SIFT, y_train_SIFT)\n",
    "print('Accuracy of svm_SIFT classifier on training set: {:.2f}'.format(svm_SIFT.score(X_train_SIFT, y_train_SIFT)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.82\n",
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of svm_ORB classifier on training set: 0.89\n"
     ]
    }
   ],
   "source": [
    "X_train_ORB = np.stack(trainHistogramsList_ORB, axis= 0)\n",
    "# Convert Categorical Data For Scikit-Learn\n",
    "\n",
    "labelEncoder_ORB = preprocessing.LabelEncoder()\n",
    "labelEncoder_ORB.fit(trainTargetsList_ORB)\n",
    "#convert the categories from strings to names\n",
    "y_train_ORB = labelEncoder_ORB.transform(trainTargetsList_ORB)\n",
    "\n",
    "knn_ORB = KNeighborsClassifier()\n",
    "knn_ORB.fit(X_train_ORB, y_train_ORB)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'.format(knn_ORB.score(X_train_ORB, y_train_ORB)))\n",
    "\n",
    "clf_ORB = DecisionTreeClassifier().fit(X_train_ORB, y_train_ORB)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(clf_ORB.score(X_train_ORB, y_train_ORB)))\n",
    "\n",
    "svm_ORB = SVC()\n",
    "svm_ORB.fit(X_train_ORB, y_train_ORB)\n",
    "print('Accuracy of svm_ORB classifier on training set: {:.2f}'.format(svm_ORB.score(X_train_ORB, y_train_ORB)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.79\n",
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of svm_SURF classifier on training set: 0.89\n"
     ]
    }
   ],
   "source": [
    "X_train_SURF = np.stack(trainHistogramsList_SURF, axis= 0)\n",
    "# Convert Categorical Data For Scikit-Learn\n",
    "\n",
    "labelEncoder_SURF = preprocessing.LabelEncoder()\n",
    "labelEncoder_SURF.fit(trainTargetsList_SURF)\n",
    "#convert the categories from strings to names\n",
    "y_train_SURF = labelEncoder_SURF.transform(trainTargetsList_SURF)\n",
    "\n",
    "knn_SURF = KNeighborsClassifier()\n",
    "knn_SURF.fit(X_train_SURF, y_train_SURF)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'.format(knn_SURF.score(X_train_SURF, y_train_SURF)))\n",
    "\n",
    "clf_SURF = DecisionTreeClassifier().fit(X_train_SURF, y_train_SURF)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(clf_SURF.score(X_train_SURF, y_train_SURF)))\n",
    "\n",
    "svm_SURF = SVC()\n",
    "svm_SURF.fit(X_train_SURF, y_train_SURF)\n",
    "print('Accuracy of svm_SURF classifier on training set: {:.2f}'.format(svm_SURF.score(X_train_SURF, y_train_SURF)))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.68\n",
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of svm_SIFT_ms classifier on training set: 0.68\n"
     ]
    }
   ],
   "source": [
    "X_train_SIFT_ms = np.stack(trainHistogramsList_SIFT_ms, axis= 0)\n",
    "# Convert Categorical Data For Scikit-Learn\n",
    "\n",
    "labelEncoder_SIFT_ms = preprocessing.LabelEncoder()\n",
    "labelEncoder_SIFT_ms.fit(trainTargetsList_SIFT_ms)\n",
    "#convert the categories from strings to names\n",
    "y_train_SIFT_ms = labelEncoder_SIFT_ms.transform(trainTargetsList_SIFT_ms)\n",
    "\n",
    "knn_SIFT_ms = KNeighborsClassifier()\n",
    "knn_SIFT_ms.fit(X_train_SIFT_ms, y_train_SIFT_ms)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'.format(knn_SIFT_ms.score(X_train_SIFT_ms, y_train_SIFT_ms)))\n",
    "\n",
    "clf_SIFT_ms = DecisionTreeClassifier().fit(X_train_SIFT_ms, y_train_SIFT_ms)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(clf_SIFT_ms.score(X_train_SIFT_ms, y_train_SIFT_ms)))\n",
    "\n",
    "svm_SIFT_ms = SVC()\n",
    "svm_SIFT_ms.fit(X_train_SIFT_ms, y_train_SIFT_ms)\n",
    "print('Accuracy of svm_SIFT_ms classifier on training set: {:.2f}'.format(svm_SIFT_ms.score(X_train_SIFT_ms, y_train_SIFT_ms)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.75\n",
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of svm_ORB_ms classifier on training set: 0.86\n"
     ]
    }
   ],
   "source": [
    "X_train_ORB_ms = np.stack(trainHistogramsList_ORB_ms, axis= 0)\n",
    "# Convert Categorical Data For Scikit-Learn\n",
    "\n",
    "labelEncoder_ORB_ms = preprocessing.LabelEncoder()\n",
    "labelEncoder_ORB_ms.fit(trainTargetsList_ORB_ms)\n",
    "#convert the categories from strings to names\n",
    "y_train_ORB_ms = labelEncoder_ORB_ms.transform(trainTargetsList_ORB_ms)\n",
    "\n",
    "knn_ORB_ms = KNeighborsClassifier()\n",
    "knn_ORB_ms.fit(X_train_ORB_ms, y_train_ORB_ms)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'.format(knn_ORB_ms.score(X_train_ORB_ms, y_train_ORB_ms)))\n",
    "\n",
    "clf_ORB_ms = DecisionTreeClassifier().fit(X_train_ORB_ms, y_train_ORB_ms)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(clf_ORB_ms.score(X_train_ORB_ms, y_train_ORB_ms)))\n",
    "\n",
    "svm_ORB_ms = SVC()\n",
    "svm_ORB_ms.fit(X_train_ORB_ms, y_train_ORB_ms)\n",
    "print('Accuracy of svm_ORB_ms classifier on training set: {:.2f}'.format(svm_ORB_ms.score(X_train_ORB_ms, y_train_ORB_ms)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.71\n",
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of svm_SURF_ms classifier on training set: 0.75\n"
     ]
    }
   ],
   "source": [
    "X_train_SURF_ms = np.stack(trainHistogramsList_SURF_ms, axis= 0)\n",
    "# Convert Categorical Data For Scikit-Learn\n",
    "\n",
    "labelEncoder_SURF_ms = preprocessing.LabelEncoder()\n",
    "labelEncoder_SURF_ms.fit(trainTargetsList_SURF_ms)\n",
    "#convert the categories from strings to names\n",
    "y_train_SURF_ms = labelEncoder_SURF_ms.transform(trainTargetsList_SURF_ms)\n",
    "\n",
    "knn_SURF_ms = KNeighborsClassifier()\n",
    "knn_SURF_ms.fit(X_train_SURF_ms, y_train_SURF_ms)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'.format(knn_SURF_ms.score(X_train_SURF_ms, y_train_SURF_ms)))\n",
    "\n",
    "clf_SURF_ms = DecisionTreeClassifier().fit(X_train_SURF_ms, y_train_SURF_ms)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(clf_SURF_ms.score(X_train_SURF_ms, y_train_SURF_ms)))\n",
    "\n",
    "svm_SURF_ms = SVC()\n",
    "svm_SURF_ms.fit(X_train_SURF_ms, y_train_SURF_ms)\n",
    "print('Accuracy of svm_SURF_ms classifier on training set: {:.2f}'.format(svm_SURF_ms.score(X_train_SURF_ms, y_train_SURF_ms)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear some space\n",
    "del  trainImages, trainBoVWFeatureVals_SIFT,trainBoVWFeatureVals_SURF\n",
    "del trainBoVWFeatureVals_ORB, trainDataFeatures_SIFT,trainDataFeatures_ORB\n",
    "del trainDataFeatures_SURF, TrainDescriptorList_SIFT,TrainDescriptorList_ORB\n",
    "del TrainDescriptorList_SURF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . Finished parsing images. What is next?\n",
      " . Finished parsing images. What is next?\n"
     ]
    }
   ],
   "source": [
    "#load the train images\n",
    "testImages = load_images_from_folder(TestImagesFilePath, inputImageSize)  # take all images category by category for train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . start detecting points and calculating features for a given image set\n",
      " . finished detecting points and calculating features for a given image set\n",
      " . finished detecting points and calculating features for a given image set\n",
      " . start detecting points and calculating features for a given image set\n",
      " . finished detecting points and calculating features for a given image set\n",
      " . finished detecting points and calculating features for a given image set\n",
      " . start detecting points and calculating features for a given image set\n",
      " . finished detecting points and calculating features for a given image set\n",
      " . finished detecting points and calculating features for a given image set\n"
     ]
    }
   ],
   "source": [
    "testDataFeatures_SIFT = detector_features(testImages, cv2.xfeatures2d.SIFT_create())\n",
    "testDataFeatures_ORB = detector_features(testImages, cv2.ORB_create())\n",
    "testDataFeatures_SURF = detector_features(testImages, cv2.xfeatures2d.SURF_create(400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the descriptor list which is unordered one\n",
    "testDescriptorList_SIFT = testDataFeatures_SIFT[0]\n",
    "testDescriptorList_ORB = testDataFeatures_ORB[0]\n",
    "testDescriptorList_SURF = testDataFeatures_SURF[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the sift feature values that is seperated class by class for train data, we need this to calculate the histograms\n",
    "testBoVWFeatureVals_SIFT = testDataFeatures_SIFT[1]\n",
    "\n",
    "testBoVWFeatureVals_ORB = testDataFeatures_ORB[1]\n",
    "\n",
    "testBoVWFeatureVals_SURF = testDataFeatures_SURF[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toExcel (FeatureExtraction, clusteringTech ,\n",
    "             dataRatio, Classifier,  X_train, X_test, \n",
    "             y_train,y_test,y_pred_train,  y_pred_test):\n",
    "    \n",
    "    #calculate the scores\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "    pre_train = precision_score(y_train, y_pred_train, average='macro', zero_division=1)\n",
    "    pre_test = precision_score(y_test, y_pred_test, average='macro', zero_division = 1)\n",
    "    rec_train = recall_score(y_train, y_pred_train, average='macro')\n",
    "    rec_test = recall_score(y_test, y_pred_test, average='macro')\n",
    "    f1_train = f1_score(y_train, y_pred_train, average='macro')\n",
    "    f1_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "    \n",
    "    #df\n",
    "    results_DF.loc[len(results_DF)] = [FeatureExtraction ] + [clusteringTech] \\\n",
    "                                      +  [dataRatio] + [Classifier] + [acc_train]\\\n",
    "                                      + [pre_train]  + [rec_train] + [f1_train] \\\n",
    "                                      + [acc_test]   + [pre_test] + [rec_test] + [f1_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the test input / test output format\n",
    "#create the train input train output format\n",
    "testHistogramsList_SIFT, testTargetsList_SIFT = mapFeatureValsToHistogram(\n",
    "    testBoVWFeatureVals_SIFT, visualWords_SIFT, TrainedKmeansModel_SIFT)\n",
    "X_test_SIFT = np.array(testHistogramsList_SIFT)\n",
    "\n",
    "y_test_SIFT = labelEncoder_SIFT.transform(testTargetsList_SIFT)\n",
    "\n",
    "y_pred_train_SIFT = clf_SIFT.predict(X_train_SIFT )\n",
    "y_pred_test_SIFT = clf_SIFT.predict(X_test_SIFT)\n",
    "toExcel('SIFT', 'KNN', '60:40', 'clf',\n",
    "        X_train_SIFT, X_test_SIFT,\n",
    "        y_train_SIFT, y_test_SIFT,\n",
    "        y_pred_train_SIFT, y_pred_test_SIFT)\n",
    "\n",
    "y_pred_train_SIFT = knn_SIFT.predict(X_train_SIFT)\n",
    "y_pred_test_SIFT = knn_SIFT.predict(X_test_SIFT)\n",
    "toExcel('SIFT', 'KNN','60:40', 'KNN',\n",
    "        X_train_SIFT, X_test_SIFT, y_train_SIFT,\n",
    "        y_test_SIFT,y_pred_train_SIFT, y_pred_test_SIFT)\n",
    "\n",
    "y_pred_train_SIFT = svm_SIFT.predict(X_train_SIFT)\n",
    "y_pred_test_SIFT = svm_SIFT.predict(X_test_SIFT)\n",
    "toExcel('SIFT', 'KNN','60:40', 'SVM',\n",
    "        X_train_SIFT, X_test_SIFT, y_train_SIFT,\n",
    "        y_test_SIFT,y_pred_train_SIFT, y_pred_test_SIFT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the test input / test output format\n",
    "#create the train input train output format\n",
    "testHistogramsList_ORB, testTargetsList_ORB = mapFeatureValsToHistogram(\n",
    "    testBoVWFeatureVals_ORB, visualWords_ORB, TrainedKmeansModel_ORB)\n",
    "X_test_ORB = np.array(testHistogramsList_ORB)\n",
    "y_test_ORB = labelEncoder_ORB.transform(testTargetsList_ORB)\n",
    "y_pred_train_ORB = clf_ORB.predict(X_train_ORB )\n",
    "y_pred_test_ORB = clf_ORB.predict(X_test_ORB)\n",
    "\n",
    "toExcel('ORB', 'KNN', '60:40', 'clf',\n",
    "        X_train_ORB, X_test_ORB, y_train_ORB,\n",
    "        y_test_ORB,y_pred_train_ORB, y_pred_test_ORB)\n",
    "\n",
    "y_pred_train_ORB = knn_ORB.predict(X_train_ORB)\n",
    "y_pred_test_ORB = knn_ORB.predict(X_test_ORB)\n",
    "toExcel('ORB', 'KNN', '60:40', 'KNN',\n",
    "        X_train_ORB, X_test_ORB, y_train_ORB,\n",
    "        y_test_ORB,y_pred_train_ORB, y_pred_test_ORB)\n",
    "\n",
    "y_pred_train_ORB = svm_ORB.predict(X_train_ORB)\n",
    "y_pred_test_ORB = svm_ORB.predict(X_test_ORB)\n",
    "toExcel('ORB', 'KNN', '60:40', 'SVM',\n",
    "        X_train_ORB, X_test_ORB, y_train_ORB,\n",
    "        y_test_ORB,y_pred_train_ORB, y_pred_test_ORB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the test input / test output format\n",
    "#create the train input train output format\n",
    "testHistogramsList_SURF, testTargetsList_SURF = mapFeatureValsToHistogram(\n",
    "    testBoVWFeatureVals_SURF, visualWords_SURF, TrainedKmeansModel_SURF)\n",
    "X_test_SURF = np.array(testHistogramsList_SURF)\n",
    "y_test_SURF = labelEncoder_SURF.transform(testTargetsList_SURF)\n",
    "y_pred_train_SURF = clf_SURF.predict(X_train_SURF )\n",
    "y_pred_test_SURF = clf_SURF.predict(X_test_SURF)\n",
    "\n",
    "toExcel('SURF', 'KNN', '60:40', 'clf',\n",
    "        X_train_SURF, X_test_SURF, y_train_SURF,\n",
    "        y_test_SURF,y_pred_train_SURF, y_pred_test_SURF)\n",
    "\n",
    "\n",
    "y_pred_train_SURF = knn_SURF.predict(X_train_SURF)\n",
    "y_pred_test_SURF = knn_SURF.predict(X_test_SURF)\n",
    "toExcel('SURF', 'KNN', '60:40', 'KNN',\n",
    "         X_train_SURF, X_test_SURF, y_train_SURF,\n",
    "        y_test_SURF,y_pred_train_SURF, y_pred_test_SURF)\n",
    "\n",
    "y_pred_train_ORB = svm_SURF.predict(X_train_SURF)\n",
    "y_pred_test_ORB = svm_SURF.predict(X_test_SURF)\n",
    "toExcel('SURF', 'KNN', '60:40', 'SVM',\n",
    "        X_train_SURF, X_test_SURF, y_train_SURF,\n",
    "        y_test_SURF,y_pred_train_SURF, y_pred_test_SURF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the test input / test output format\n",
    "#create the train input train output format\n",
    "testHistogramsList_SIFT_ms, testTargetsList_SIFT_ms = mapFeatureValsToHistogram(\n",
    "    testBoVWFeatureVals_SIFT, visualWords_SIFT_ms, TrainedMsModel_SIFT)\n",
    "X_test_SIFT_ms = np.array(testHistogramsList_SIFT_ms)\n",
    "y_test_SIFT_ms = labelEncoder_SIFT_ms.transform(testTargetsList_SIFT_ms)\n",
    "y_pred_train_SIFT_ms = clf_SIFT_ms.predict(X_train_SIFT_ms )\n",
    "y_pred_test_SIFT_ms = clf_SIFT_ms.predict(X_test_SIFT_ms)\n",
    "toExcel('SURF', 'MeanShift', '60:40', 'clf',\n",
    "        X_train_SIFT_ms, X_test_SIFT_ms, y_train_SIFT_ms,\n",
    "        y_test_SIFT_ms,y_pred_train_SIFT_ms, y_pred_test_SIFT_ms)\n",
    "\n",
    "\n",
    "y_pred_train_SIFT_ms = knn_SIFT_ms.predict(X_train_SIFT_ms)\n",
    "y_pred_test_SIFT_ms = knn_SIFT_ms.predict(X_test_SIFT_ms)\n",
    "toExcel('SURF', 'MeanShift', '60:40', 'KNN',\n",
    "        X_train_SIFT_ms, X_test_SIFT_ms, y_train_SIFT_ms,\n",
    "        y_test_SIFT_ms,y_pred_train_SIFT_ms, y_pred_test_SIFT_ms)\n",
    "\n",
    "y_pred_train_SIFT_ms = svm_SIFT_ms.predict(X_train_SIFT_ms)\n",
    "y_pred_test_SIFT_ms = svm_SIFT_ms.predict(X_test_SIFT_ms)\n",
    "toExcel('SURF', 'MeanShift', '60:40', 'CVM',\n",
    "        X_train_SIFT_ms, X_test_SIFT_ms, y_train_SIFT_ms,\n",
    "        y_test_SIFT_ms,y_pred_train_SIFT_ms, y_pred_test_SIFT_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the test input / test output format\n",
    "#create the train input train output format\n",
    "testHistogramsList_ORB_ms, testTargetsList_ORB_ms = mapFeatureValsToHistogram(\n",
    "    testBoVWFeatureVals_ORB, visualWords_ORB_ms, TrainedMsModel_ORB)\n",
    "X_test_ORB_ms = np.array(testHistogramsList_ORB_ms)\n",
    "y_test_ORB_ms = labelEncoder_ORB_ms.transform(testTargetsList_ORB_ms)\n",
    "y_pred_train_ORB_ms = clf_ORB_ms.predict(X_train_ORB_ms )\n",
    "y_pred_test_ORB_ms = clf_ORB_ms.predict(X_test_ORB_ms)\n",
    "toExcel('ORB', 'MeanShift', '60:40', 'clf',\n",
    "        X_train_ORB_ms, X_test_ORB_ms, y_train_ORB_ms,\n",
    "        y_test_ORB_ms,y_pred_train_ORB_ms, y_pred_test_ORB_ms)\n",
    "\n",
    "y_pred_train_ORB_ms = knn_ORB_ms.predict(X_train_ORB_ms)\n",
    "y_pred_test_ORB_ms = knn_ORB_ms.predict(X_test_ORB_ms)\n",
    "toExcel('ORB', 'MeanShift', '60:40', 'KNN',\n",
    "        X_train_ORB_ms, X_test_ORB_ms, y_train_ORB_ms,\n",
    "        y_test_ORB_ms,y_pred_train_ORB_ms, y_pred_test_ORB_ms)\n",
    "\n",
    "y_pred_train_ORB_ms = svm_ORB_ms.predict(X_train_ORB_ms)\n",
    "y_pred_test_ORB_ms = svm_ORB_ms.predict(X_test_ORB_ms)\n",
    "toExcel('ORB', 'MeanShift', '60:40', 'SVM',\n",
    "        X_train_ORB_ms, X_test_ORB_ms, y_train_ORB_ms,\n",
    "        y_test_ORB_ms,y_pred_train_ORB_ms, y_pred_test_ORB_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the test input / test output format\n",
    "#create the train input train output format\n",
    "testHistogramsList_SURF_ms, testTargetsList_SURF_ms = mapFeatureValsToHistogram(\n",
    "    testBoVWFeatureVals_SURF, visualWords_SURF_ms, TrainedMsModel_SURF)\n",
    "X_test_SURF_ms = np.array(testHistogramsList_SURF_ms)\n",
    "y_test_SURF_ms = labelEncoder_SURF_ms.transform(testTargetsList_SURF_ms)\n",
    "y_pred_train_SURF_ms = clf_SURF_ms.predict(X_train_SURF_ms )\n",
    "y_pred_test_SURF_ms = clf_SURF_ms.predict(X_test_SURF_ms)\n",
    "toExcel('SURF', 'MeanShift', '60:40', 'clf',\n",
    "        X_train_SURF_ms, X_test_SURF_ms, y_train_SURF_ms,\n",
    "        y_test_SURF_ms,y_pred_train_SURF_ms, y_pred_test_SURF_ms)\n",
    "\n",
    "y_pred_train_SURF_ms = knn_SURF_ms.predict(X_train_SURF_ms )\n",
    "y_pred_test_SURF_ms = knn_SURF_ms.predict(X_test_SURF_ms)\n",
    "toExcel('SURF', 'MeanShift', '60:40', 'KNN',\n",
    "        X_train_SURF_ms, X_test_SURF_ms, y_train_SURF_ms,\n",
    "        y_test_SURF_ms,y_pred_train_SURF_ms, y_pred_test_SURF_ms)\n",
    "\n",
    "y_pred_train_SURF_ms = svm_SURF_ms.predict(X_train_SURF_ms )\n",
    "y_pred_test_SURF_ms = svm_SURF_ms.predict(X_test_SURF_ms)\n",
    "toExcel('SURF', 'MeanShift', '60:40', 'SVM',\n",
    "        X_train_SURF_ms, X_test_SURF_ms, y_train_SURF_ms,\n",
    "        y_test_SURF_ms,y_pred_train_SURF_ms, y_pred_test_SURF_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FeatureExtraction</th>\n",
       "      <th>Clustering Detection</th>\n",
       "      <th>Train Data ratio</th>\n",
       "      <th>Classifier Used</th>\n",
       "      <th>Accuracy(tr)</th>\n",
       "      <th>Precision(tr)</th>\n",
       "      <th>Recal(tr)</th>\n",
       "      <th>F1 score (tr)</th>\n",
       "      <th>Accuracy (te)</th>\n",
       "      <th>Precision (te)</th>\n",
       "      <th>Recal(te)</th>\n",
       "      <th>F1 score (te)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SIFT</td>\n",
       "      <td>KNN</td>\n",
       "      <td>60:40</td>\n",
       "      <td>clf</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.496779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SIFT</td>\n",
       "      <td>KNN</td>\n",
       "      <td>60:40</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.4725</td>\n",
       "      <td>0.472063</td>\n",
       "      <td>0.4725</td>\n",
       "      <td>0.470431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SIFT</td>\n",
       "      <td>KNN</td>\n",
       "      <td>60:40</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.4650</td>\n",
       "      <td>0.441967</td>\n",
       "      <td>0.4650</td>\n",
       "      <td>0.406067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORB</td>\n",
       "      <td>KNN</td>\n",
       "      <td>60:40</td>\n",
       "      <td>clf</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.558700</td>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.540363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORB</td>\n",
       "      <td>KNN</td>\n",
       "      <td>60:40</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.821201</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.560024</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.559956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORB</td>\n",
       "      <td>KNN</td>\n",
       "      <td>60:40</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.891613</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.550080</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.549820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SURF</td>\n",
       "      <td>KNN</td>\n",
       "      <td>60:40</td>\n",
       "      <td>clf</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.494103</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.475038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SURF</td>\n",
       "      <td>KNN</td>\n",
       "      <td>60:40</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.451172</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.444104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SURF</td>\n",
       "      <td>KNN</td>\n",
       "      <td>60:40</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.451172</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.444104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SURF</td>\n",
       "      <td>MeanShift</td>\n",
       "      <td>60:40</td>\n",
       "      <td>clf</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.521978</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.508951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SURF</td>\n",
       "      <td>MeanShift</td>\n",
       "      <td>60:40</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.459855</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.459514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SURF</td>\n",
       "      <td>MeanShift</td>\n",
       "      <td>60:40</td>\n",
       "      <td>CVM</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.4825</td>\n",
       "      <td>0.474294</td>\n",
       "      <td>0.4825</td>\n",
       "      <td>0.437618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ORB</td>\n",
       "      <td>MeanShift</td>\n",
       "      <td>60:40</td>\n",
       "      <td>clf</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.512142</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.487394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ORB</td>\n",
       "      <td>MeanShift</td>\n",
       "      <td>60:40</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.751282</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.749681</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.494156</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.476087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ORB</td>\n",
       "      <td>MeanShift</td>\n",
       "      <td>60:40</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.856410</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.552793</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.543969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SURF</td>\n",
       "      <td>MeanShift</td>\n",
       "      <td>60:40</td>\n",
       "      <td>clf</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.497472</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.496111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SURF</td>\n",
       "      <td>MeanShift</td>\n",
       "      <td>60:40</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.526415</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.504125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SURF</td>\n",
       "      <td>MeanShift</td>\n",
       "      <td>60:40</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.462235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FeatureExtraction Clustering Detection Train Data ratio Classifier Used  \\\n",
       "0               SIFT                  KNN            60:40             clf   \n",
       "1               SIFT                  KNN            60:40             KNN   \n",
       "2               SIFT                  KNN            60:40             SVM   \n",
       "3                ORB                  KNN            60:40             clf   \n",
       "4                ORB                  KNN            60:40             KNN   \n",
       "5                ORB                  KNN            60:40             SVM   \n",
       "6               SURF                  KNN            60:40             clf   \n",
       "7               SURF                  KNN            60:40             KNN   \n",
       "8               SURF                  KNN            60:40             SVM   \n",
       "9               SURF            MeanShift            60:40             clf   \n",
       "10              SURF            MeanShift            60:40             KNN   \n",
       "11              SURF            MeanShift            60:40             CVM   \n",
       "12               ORB            MeanShift            60:40             clf   \n",
       "13               ORB            MeanShift            60:40             KNN   \n",
       "14               ORB            MeanShift            60:40             SVM   \n",
       "15              SURF            MeanShift            60:40             clf   \n",
       "16              SURF            MeanShift            60:40             KNN   \n",
       "17              SURF            MeanShift            60:40             SVM   \n",
       "\n",
       "    Accuracy(tr)  Precision(tr)  Recal(tr)  F1 score (tr)  Accuracy (te)  \\\n",
       "0       1.000000       1.000000   1.000000       1.000000         0.5000   \n",
       "1       0.571429       0.577778   0.571429       0.562500         0.4725   \n",
       "2       0.785714       0.811111   0.785714       0.781250         0.4650   \n",
       "3       1.000000       1.000000   1.000000       1.000000         0.5525   \n",
       "4       0.821429       0.823077   0.821429       0.821201         0.5600   \n",
       "5       0.892857       0.911765   0.892857       0.891613         0.5500   \n",
       "6       1.000000       1.000000   1.000000       1.000000         0.4950   \n",
       "7       0.785714       0.791667   0.785714       0.784615         0.4550   \n",
       "8       0.785714       0.791667   0.785714       0.784615         0.4550   \n",
       "9       1.000000       1.000000   1.000000       1.000000         0.5200   \n",
       "10      0.678571       0.679487   0.678571       0.678161         0.4600   \n",
       "11      0.678571       0.738095   0.678571       0.657143         0.4825   \n",
       "12      1.000000       1.000000   1.000000       1.000000         0.5100   \n",
       "13      0.750000       0.751282   0.750000       0.749681         0.4950   \n",
       "14      0.857143       0.864583   0.857143       0.856410         0.5500   \n",
       "15      1.000000       1.000000   1.000000       1.000000         0.4975   \n",
       "16      0.714286       0.733333   0.714286       0.708333         0.5225   \n",
       "17      0.750000       0.833333   0.750000       0.733333         0.5000   \n",
       "\n",
       "    Precision (te)  Recal(te)  F1 score (te)  \n",
       "0         0.500000     0.5000       0.496779  \n",
       "1         0.472063     0.4725       0.470431  \n",
       "2         0.441967     0.4650       0.406067  \n",
       "3         0.558700     0.5525       0.540363  \n",
       "4         0.560024     0.5600       0.559956  \n",
       "5         0.550080     0.5500       0.549820  \n",
       "6         0.494103     0.4950       0.475038  \n",
       "7         0.451172     0.4550       0.444104  \n",
       "8         0.451172     0.4550       0.444104  \n",
       "9         0.521978     0.5200       0.508951  \n",
       "10        0.459855     0.4600       0.459514  \n",
       "11        0.474294     0.4825       0.437618  \n",
       "12        0.512142     0.5100       0.487394  \n",
       "13        0.494156     0.4950       0.476087  \n",
       "14        0.552793     0.5500       0.543969  \n",
       "15        0.497472     0.4975       0.496111  \n",
       "16        0.526415     0.5225       0.504125  \n",
       "17        0.500000     0.5000       0.462235  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DF.to_excel('10_200Results.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
